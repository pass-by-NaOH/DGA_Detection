{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一、数据处理与展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "# 加载数据\n",
    "filename = 'dataset/dga_domains_full.csv'\n",
    "file_dataframe = read_file(filename)\n",
    "# 1表示DGA域名 0表示正常合法域名\n",
    "file_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二、数据向量化与分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 数据向量化\n",
    "list_Domain = file_dataframe['Domain'].tolist()\n",
    "list_Label = file_dataframe['Label'].tolist()\n",
    "# 返回数据矩阵，数据标签，最大单个域名长度，词字典\n",
    "data_vector, list_label, max_data_len, valid_chars = domain_to_vector(list_Domain, list_Label)\n",
    "# 数据向量示例\n",
    "str(data_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "# 73开\n",
    "split_size = 0.3 # 测试集占的比例\n",
    "train_data, test_data, train_label, test_label = data_split(data_vector, list_label, split_size)\n",
    "\n",
    "max_features = len(valid_chars) + 1 # 数据集特征大小\n",
    "print(\"数据集大小：{};\".format(len(list_Domain)) + '最大域名长度：{};'.format(max_data_len) + \"训练集大小：{};\".format(len(train_data)) + \"测试集大小：{};\".format(len(test_data)))\n",
    "\n",
    "# 计算合法域名和DGA域名\n",
    "list_B = []\n",
    "list_M = []\n",
    "for i in range(len(list_Domain)):\n",
    "    if list_Label[i] == 0:\n",
    "        list_B.append(list_Domain[i])\n",
    "    else:\n",
    "        list_M.append(list_Domain[i])\n",
    "print(\"合法域名大小：{};\".format(len(list_B)) + \"DGA域名大小：{};\".format(len(list_M)))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三、CNN-At-LSTM模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "cnn_at_lstm_model = cnn_At_lstm(max_features, max_data_len)\n",
    "# 训练数据集\n",
    "start_time = time.time()\n",
    "# 迭代20次，交叉验证集的比例为10%\n",
    "history_cnn_at_lstm = cnn_at_lstm_model.fit(train_data, train_label, epochs=EPOCH, batch_size=BATCH_SIZE, shuffle=True, validation_split=0.1)\n",
    "end_time = time.time()\n",
    "print(\"花费时间为{}\".format(end_time-start_time))\n",
    "# 测试集的最终损失率, 准确律\n",
    "loss_cnn_at_lstm ,tp, fp, tn, fn, accuracy_cnn_at_lstm, precision, recall, auc= cnn_at_lstm_model.evaluate(test_data, test_label, batch_size=BATCH_SIZE)\n",
    "print('测试集最终损失值:', loss_cnn_at_lstm)\n",
    "print('测试集准确率:', accuracy_cnn_at_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# 以json的形式保存模型的架构\n",
    "modelPath = \"models/cnn_at_lstm_model.json\"\n",
    "model_save_json(cnn_at_lstm_model, modelPath)\n",
    "\n",
    "# 保存训练时的参数\n",
    "historyPath1 = \"models/history_cnn_at_lstm.txt\"\n",
    "save_history(history_cnn_at_lstm, historyPath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四、CNN_LSTM模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425184/425184 [==============================] - 100s 236us/sample - loss: 0.0294 - tp: 4438970.5000 - fp: 116360.4922 - tn: 4475340.0000 - fn: 158112.0156 - accuracy: 0.9701 - precision: 0.9744 - recall: 0.9656 - auc: 0.9957 - val_loss: 0.1704 - val_tp: 4555331.5000 - val_fp: 118055.5859 - val_tn: 4591509.0000 - val_fn: 160145.1719 - val_accuracy: 0.9705 - val_precision: 0.9747 - val_recall: 0.9660 - val_auc: 0.9958\n",
      "花费时间为7807.063976049423\n",
      "202470/202470 [==============================] - 17s 83us/sample - loss: 0.1729 - tp: 4614398.0000 - fp: 120554.0547 - tn: 4651534.5000 - fn: 163364.8906 - accuracy: 0.9703 - precision: 0.9745 - recall: 0.9658 - auc: 0.9956\n",
      "测试集最终损失值: 0.17285906068526968\n",
      "测试集准确率: 0.97027147\n",
      "模型的架构json文件保存完成！\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "cnn_lstm_model = cnn_lstm(max_features, max_data_len)\n",
    "# 训练数据集\n",
    "start_time = time.time()\n",
    "# 迭代20次，交叉验证集的比例为10%\n",
    "history_cnn_lstm = cnn_lstm_model.fit(train_data, train_label, epochs=EPOCH, batch_size=BATCH_SIZE, shuffle=True,validation_split=0.1)\n",
    "end_time = time.time()\n",
    "print(\"花费时间为{}\".format(end_time - start_time))\n",
    "# 测试集的最终损失率, 准确律\n",
    "loss_cnn_lstm, tp, fp, tn, fn, accuracy_cnn_lstm, precision, recall, auc = cnn_lstm_model.evaluate(test_data,\n",
    "                                                                                                   test_label,\n",
    "                                                                                                   batch_size=BATCH_SIZE)\n",
    "print('测试集最终损失值:', loss_cnn_lstm)\n",
    "print('测试集准确率:', accuracy_cnn_lstm)\n",
    "# 保存模型\n",
    "# 以json的形式保存模型的架构\n",
    "modelPath = \"models/cnn_lstm_model.json\"\n",
    "model_save_json(cnn_lstm_model, modelPath)\n",
    "\n",
    "# 保存训练时的参数\n",
    "historyPath1 = \"models/history_cnn_lstm.txt\"\n",
    "save_history(history_cnn_lstm, historyPath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五、CNN模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 63, 128)      4992        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 63, 128)      32896       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 63, 128)      49280       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 63, 128)      65664       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128)          512         global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 384)          0           dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            385         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 154,753\n",
      "Trainable params: 153,985\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "Train on 425184 samples, validate on 47243 samples\n",
      "Epoch 1/20\n",
      "425184/425184 [==============================] - 57s 134us/sample - loss: 0.3066 - tp: 86537.0938 - fp: 9930.6162 - tn: 96416.8516 - fn: 19787.4551 - accuracy: 0.8493 - precision: 0.8887 - recall: 0.7976 - auc: 0.9179 - val_loss: 0.2658 - val_tp: 185912.8594 - val_fp: 19392.6172 - val_tn: 204898.6875 - val_fn: 38723.4805 - val_accuracy: 0.8705 - val_precision: 0.9055 - val_recall: 0.8276 - val_auc: 0.9379\n",
      "Epoch 2/20\n",
      "425184/425184 [==============================] - 54s 126us/sample - loss: 0.2609 - tp: 287081.1250 - fp: 28277.8105 - tn: 314010.3438 - fn: 55730.2773 - accuracy: 0.8769 - precision: 0.9101 - recall: 0.8366 - auc: 0.9433 - val_loss: 0.2355 - val_tp: 389160.1875 - val_fp: 37236.1523 - val_tn: 423122.3438 - val_fn: 71836.3594 - val_accuracy: 0.8816 - val_precision: 0.9127 - val_recall: 0.8442 - val_auc: 0.9473\n",
      "Epoch 3/20\n",
      "425184/425184 [==============================] - 54s 127us/sample - loss: 0.2470 - tp: 491822.4375 - fp: 46025.5547 - tn: 532456.4375 - fn: 87222.2812 - accuracy: 0.8847 - precision: 0.9144 - recall: 0.8491 - auc: 0.9499 - val_loss: 0.2362 - val_tp: 594662.5000 - val_fp: 54414.8867 - val_tn: 642010.1875 - val_fn: 102694.2031 - val_accuracy: 0.8873 - val_precision: 0.9162 - val_recall: 0.8527 - val_auc: 0.9520\n",
      "Epoch 4/20\n",
      "425184/425184 [==============================] - 54s 127us/sample - loss: 0.2385 - tp: 697722.3750 - fp: 62557.6914 - tn: 752042.6875 - fn: 117630.2734 - accuracy: 0.8894 - precision: 0.9177 - recall: 0.8556 - auc: 0.9537 - val_loss: 0.2219 - val_tp: 801404.8750 - val_fp: 70845.4375 - val_tn: 861646.8125 - val_fn: 132311.2500 - val_accuracy: 0.8911 - val_precision: 0.9188 - val_recall: 0.8583 - val_auc: 0.9550\n",
      "Epoch 5/20\n",
      "425184/425184 [==============================] - 54s 127us/sample - loss: 0.2318 - tp: 905351.0000 - fp: 79052.2969 - tn: 971520.8750 - fn: 146456.3281 - accuracy: 0.8927 - precision: 0.9197 - recall: 0.8607 - auc: 0.9562 - val_loss: 0.2132 - val_tp: 1009739.8750 - val_fp: 87417.2109 - val_tn: 1081141.7500 - val_fn: 160335.9688 - val_accuracy: 0.8941 - val_precision: 0.9203 - val_recall: 0.8630 - val_auc: 0.9573\n",
      "Epoch 6/20\n",
      " 75776/425184 [====>.........................] - ETA: 42s - loss: 0.2281 - tp: 1036920.5625 - fp: 89492.0234 - tn: 1109892.2500 - fn: 163781.9531 - accuracy: 0.8945 - precision: 0.9206 - recall: 0.8636 - auc: 0.9576"
     ]
    }
   ],
   "source": [
    "# 训练cnn模型\n",
    "\n",
    "cnn_model = cnn(max_features, max_data_len)\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# 训练数据集\n",
    "start_time = time.time()\n",
    "# 迭代20次，交叉验证集的比例为20%\n",
    "history_cnn = cnn_model.fit(train_data, train_label, epochs=EPOCH, batch_size=BATCH_SIZE, shuffle=True, validation_split=0.1)\n",
    "end_time = time.time()\n",
    "print(\"花费时间为{}\".format(end_time-start_time))\n",
    "# 测试集的最终损失率, 准确律\n",
    "loss_cnn ,tp, fp, tn, fn, accuracy_cnn, precision, recall, auc= cnn_model.evaluate(test_data, test_label, batch_size=BATCH_SIZE)\n",
    "print('测试集最终损失值:', loss_cnn)\n",
    "print('测试集准确率:', accuracy_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# 以json的形式保存模型的架构\n",
    "modelPath = \"models/cnn_model.json\"\n",
    "model_save_json(cnn_model, modelPath)\n",
    "# 保存训练时的参数\n",
    "historyPath2 = \"models/history_cnn.txt\"\n",
    "save_history(history_cnn, historyPath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第七、LSTM模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 训练lstm模型\n",
    "\n",
    "lstm_model = lstm(max_features, max_data_len)\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# 训练数据集\n",
    "start_time = time.time()\n",
    "# 迭代20次，交叉验证集的比例为10%\n",
    "history_lstm = lstm_model.fit(train_data, train_label, epochs=EPOCH, batch_size=BATCH_SIZE, shuffle=True, validation_split=0.1)\n",
    "end_time = time.time()\n",
    "print(\"花费时间为{}\".format(end_time - start_time))\n",
    "# 测试集的最终损失率, 准确律\n",
    "loss_lstm ,tp, fp, tn, fn, accuracy_lstm, precision, recall, auc= lstm_model.evaluate(test_data, test_label, batch_size=BATCH_SIZE)\n",
    "print('测试集最终损失值:', loss_lstm)\n",
    "print('测试集准确率:', accuracy_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# 以json的形式保存模型的架构\n",
    "modelPath = \"models/lstm_model.json\"\n",
    "model_save_json(cnn_lstm_model, modelPath)\n",
    "# 保存训练时的参数\n",
    "historyPath3 = \"models/history_lstm.txt\"\n",
    "save_history(history_lstm, historyPath3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第八、绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘图\n",
    "# 绘制cnn_at_lstm图像\n",
    "plot_MyModel(cnn_at_lstm_model, 'result_img/cnn_at_lstm_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘图accuracy, precision, recall, loss\n",
    "plot_confusion_metrics(history_cnn_lstm, 'result_img/cnn_at_lstm_metric.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘制cnn_lstm图像\n",
    "plot_MyModel(cnn_lstm_model, 'result_img/cnn_lstm_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘图accuracy, precision, recall, loss\n",
    "plot_confusion_metrics(history_cnn_lstm, 'result_img/cnn_lstm_metric.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘制cnn图像\n",
    "plot_MyModel(cnn_model, 'result_img/cnn_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘图accuracy, precision, recall, loss\n",
    "plot_confusion_metrics(history_cnn, 'result_img/cnn_model_metric.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘制lstm图像\n",
    "plot_MyModel(lstm_model, 'result_img/lstm_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘图accuracy, precision, recall, loss\n",
    "plot_confusion_metrics(history_lstm, 'result_img/lstm_model_metric.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 四个模型比较的ROC\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "cnn_at_lstm_predictions = cnn_at_lstm_model.predict(test_data, batch_size=128)\n",
    "cnn_lstm_predictions = cnn_lstm_model.predict(test_data, batch_size=128)\n",
    "cnn_predictions = cnn_model.predict(test_data, batch_size=128)\n",
    "lstm_predictions = lstm_model.predict(test_data, batch_size=128)\n",
    "\n",
    "\n",
    "# 使用roc_curve函数计算ROC曲线数据\n",
    "fpr_c_a_l, tpr_c_a_l, thresholds_c_a_l = roc_curve(test_label, cnn_at_lstm_predictions)\n",
    "fpr_c_l, tpr_c_l, thresholds_c_l = roc_curve(test_label, cnn_lstm_predictions)\n",
    "fpr_c, tpr_c, thresholds_c = roc_curve(test_label, cnn_predictions)\n",
    "fpr_l, tpr_l, thresholds_l = roc_curve(test_label, lstm_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_c_a_l, tpr_c_a_l, color='orange', lw=lw, label=\"CNN_At_LSTM Baseline\")\n",
    "plt.plot(fpr_c_l, tpr_c_l, color='red', lw=lw, label=\"CNN_LSTM Baseline\")\n",
    "plt.plot(fpr_c, tpr_c, color='green', lw=lw, label=\"CNN Baseline\")\n",
    "plt.plot(fpr_l, tpr_l, color='blue', lw=lw, label=\"LSTM Baseline\")\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('result_img/ROC_of_AllTheModel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
